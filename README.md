# Feed_Forward_Neural_Networks


A feedforward neural network, also known as a feedforward artificial neural network or simply a feedforward neural network (FNN), is a fundamental architecture in the field of artificial neural networks and machine learning. It is characterized by a series of interconnected processing units or neurons arranged in layers. The network is called "feedforward" because information flows in one direction, from the input layer through one or more hidden layers to the output layer, without any loops or feedback connections.

# 1. Architecture:

Input Layer: The input layer is responsible for receiving the initial data or features that the network will process. Each neuron in this layer represents a feature or input variable.
Hidden Layers: These layers, which can vary in number and size, are situated between the input and output layers. They perform complex transformations on the input data using weighted connections and activation functions. The term "hidden" refers to the fact that these layers are not directly observable in the input or output data.
Output Layer: The output layer produces the final predictions or classifications. The number of neurons in this layer depends on the problem type (e.g., one neuron for binary classification, multiple neurons for multi-class classification or regression).

# 2. Connections:
Each neuron in one layer is connected to every neuron in the subsequent layer, and these connections are associated with weights. These weights determine the strength of the connections and are learned during the training process.
